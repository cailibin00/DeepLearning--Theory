[Paying More Attention to Attention: Improving the Performance of Convolutional Neural Networks via Attention Transfer 原文](https://openreview.net/forum?id=Sks9_ajex)
***要写项目***
## 前言
该文章最终要的贡献就是让小规模的网络模仿教师的注意力分布，从而提升学生模型的性能

给出了注意力机制的定义
- 编码了网络在处理图像时最关注的区域
- 不同层的注意力能够捕获不同尺度的表征信息

文章给出了两种注意力
- **激活基**
- **梯度基**
![](file-20250930160830897.png)

文章要解决的问题
- 如何使得CNN学生模型利用教师的注意力map
- 如何使得学生模型不只是能够有很好的预测结果，还要是实在地学习到教师的注意力map

研究大致方向
- 文章还给出了目前（2017）的知识迁移弊端
	由fitnet引导的，利用深的，参数量少的网络来学习宽的，参数量更多的教师网络
- 流行的resnet网络由于残差连接，能够得到更好的结果
但是，深度的增加得到更好结果的本质就是参数量的增加带来的表征能力的提高，一个深深的网络和一个参数量相等的浅层网络预测结果能够达到一致，甚至更好。
并且，深层网络的并行能力很差，比较难以训练。

因此，文章致力于使用和fitnet相反的，浅层的学生网络。


## 注意力迁移

假设输入为$A∈R^{C,W,H}$ 
### 隐含假设
**隐藏神经元的绝对值，能够表征当前输入的重要指标**
- 解释
	 神经元有正有负，举个例子，正表示从暗到明，负号相反，要是没有颜色变化，就会变得很小。那么绝对值处理之后，只会表明该地方有没有显著变化。网络要关注的往往是这些关键的信息（网络可以在不同的数据集上学习表示，不一定是举例子的这样），这个时候绝对值处理往往能表示**有或无**，也就符合我们对于注意力的理解。

### 注意力映射函数

$$F_{sum} = \sum_{i=1}^{C}|A_i|$$
$$F_{sum}^p = \sum_{i=1}^{C}|A_i|^p$$
$$F_{max}^{p} = max_{i=1...C}\{A_i^p\}$$
- 合理性假设：
绝对值求和能够表示该像素点在不同的channel之中被重视程度和
p>1 : 幂处理，能够拉开被注意程度之间的差距
最大值处理，能够得到该像素在不同channel之间最被重视的程度，作为该像素点被重视程度的表征

### 测试函数建模
利用已有的建模，我们在已训练好的模型上验证，该映射函数是否确确实实能够反映模型的注意力情况。

我们关注的模型是模型相同，架构相同，但是由于 **训练策略**不同导致模型的性能出现显著差异的。
研究发现
1. 图像预测的目标确实和我们的映射关系有相关性；并且，性能更好的模型在目标的定位和目标的细节上关注的情况更好，这可能和他的性能有正相关。【下图1】
2. 不同层的注意力关注的图像部分不同。【下图2】
	 p越大，**细节剩余越少**，模型只会关注那些**激活值特别高**的区域
	 
![](file-20250930160859287.png)
![](file-20250930160917726.png)


### 训练策略-损失函数

**迁移损失的层间放置原则**：
由于 CNN 不同层的注意力图对应不同层次的特征（浅层关注低阶梯度特征、中层关注目标判别区域、高层关注完整目标），为确保学生网络在**全特征层次**上都能模仿教师，通常会**跨多个层放置注意力迁移损失**。
即不仅在某一个特定层计算师生注意力图的差异损失（就像是fitnet的策略），还会在**多个关键层**（如浅层、中层、高层）分别设置损失项，迫使学生在低、中、高各阶特征的注意力分布上均与教师对齐，避免单一层次模仿导致的特征学习片面性。
如果**分辨率**不同，可以使用插值来处理
![](file-20250930160955110.png)



**损失函数**：
$$L_{AT} = L_{cls}(W_s , x) + \beta \cdot L_{transfer} + \alpha \cdot L_{distill}$$
$$L_{transfer} = \sum_{j∈All}{  || \frac{Q^{(s)}_{j}}{||Q^{(s)}_{j} ||_2  } - \frac{Q^{(t)}_{j}}{||Q^{(t)}_{j}||_2}  ||_{p}  }$$
其中
$$Q_j = Vec< F(A) >$$
- $F$ 是上面的映射函数
- $Vec<>$ 是把他变成一个向量，二维$R^{H*W}$ 变成$R^{(HW)}$  ,
- $||Q||_2$ 是为了归一化，分子逐项相减，得到一个偏差的向量
- 将偏差的向量$||Vec||_p$ 处理(p=2)，是为了衡量两个向量偏差向量的综合程度
- $\beta$ 是权重，会逐渐缩小

### 梯度基注意力迁移

梯度基注意力的本质是 “**输入敏感图**”—— 网络对输入某位置的 “注意力程度”，由 “该位置的微小变化对网络输出决策的影响程度” 决定。
如果这个位置导数大，那就意味着它影响大。（有点扯）
给出梯度注意力的定义
$$J_{s} = \frac{\partial }{\partial x}L(W_s , x) $$
$$J_t = \frac{\partial }{\partial x} L(W_t ,x )$$
得到的梯度注意力图是：
$J ∈ R^{(C , H , W)}$ 和输入的维度一模一样

**损失函数**
$$L_{AT} = L_{cls}(W_s , x) + \frac{\beta}{2}|| J_t - J_s||_2$$

值得注意的是，该注意力迁移的计算量比较大，它包含两次反向传播，第一次是计算参数的梯度，第二次是计算X的偏导数，通过损失函数再次更新学生参数。两次计算量基本相同。





## 测试
### 测试CNN注意力
下面是在我自己的模型上，使用用p=2之后mean()处理：
在Fashion-MNIST
- 原图
![[Pasted image 20250925195116.png|200]]
- 教师和学生的处理
![[Pasted image 20250925195227.png]]
其中教师网络在最后已经收敛到一个点，实际上已经做出了决策
学生网络由于还停留在中间隐藏，还处于关注的状态

在Cifar10
- 原图
![[Pasted image 20250925204236.png|200]]
![[Pasted image 20250925204131.png|200]]
- 教师和学生的pow(2).sum(dim=1)处理
![[Pasted image 20250925202512.png]]
![[Pasted image 20250925204149.png]]

- 教师和学生的sum处理
![[Pasted image 20250925204908.png]]
![[Pasted image 20250925204945.png]]

我们发现，到后面，实际上已经脱离了注意力的范畴了
一方面，注意力关注于边界，并不是物体
一方面，后面的图过于抽象，不能使用注意力来抽象理解了


## 项目

| 模型       | 教师      | 基线     | 学生（AT+KD） | 学生（KD） |
| -------- | ------- | ------ | --------- | ------ |
| 参数量      | 2243546 | 691674 | 691674    | 691674 |
| 训练损失     | 0.174   | 0.23   | 1.75      |        |
| 训练准确     | 94.02%  | 90.14% | 90.15%    |        |
| AT损失     | -       | -      | 1.17      |        |
| **验证准确** | 89.91%  | 88.40% | 88.19%    |        |

### 教师
- 损失
![[Pasted image 20250927010019.png]]
![[Pasted image 20250927010038.png]]
- 准确率
![[Pasted image 20250927010058.png]]
![[Pasted image 20250927010113.png]]
### 基线
- 损失
![[Pasted image 20250927010527.png]]
![[Pasted image 20250927010556.png]]
- 准确率
![[Pasted image 20250927010433.png]]
![[Pasted image 20250927010453.png]]
### 学生
- AT损失
![[Pasted image 20250927010708.png]]
![[Pasted image 20250927010732.png]]
- 蒸馏损失
![[Pasted image 20250927010911.png]]
- 总损失
![[Pasted image 20250927011005.png]]
![[Pasted image 20250927010948.png]]
- 准确率
![[Pasted image 20250927011034.png]]
![[Pasted image 20250927011100.png]]
### 验证
![[Pasted image 20250927010356.png]]![[Pasted image 20250927010635.png]]
![[Pasted image 20250927011155.png]]