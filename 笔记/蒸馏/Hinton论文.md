
## 前言
我们倾向于将模型学习到的知识和其参数对应起来，这使得我们很难理解如何在保持相同知识的情况下，改变模型的形式。
文章之中提出，学习的知识最后体现在能够**正确从输入映射到输出**。知识还可以体现在这些映射结果之中，也就是模型可能还会为错误的标签赋予一定的数值，这之中包含了模型对于知识的理解，还可以说，是该***模型泛化能力***的体现。

- 注：泛化能力描述了模型在学习训练集的数据之后，理解数据并且运用到新知识的能力。

## 知识蒸馏

给出经典公式
$$SoftMax(x_i,T) = \frac{exp(x_i/T)}{\sum^{N}_{x∈X}{exp(x/T)}}$$
- 数学理解：T的增大，会把x拉回到一个小范围，由于导数的递增属性，使得他们的差距被缩小，起到了放大错误样本的功能。

在计算损失函数的时候，利用了硬标签和软标签，既要学习正确的样本，又要兼顾知识蒸馏。
在计算梯度的时候，x由于温度附带上了$1/t^2$的梯度，因此在计算损失函数时要乘回去$T^2$

### 交叉熵函数
详情请见 ___[[熵]]___ 一章节
- 教师模型生成的软标签为($p = [p_1, p_2,..., p_N]$)（N为类别数，($p_i$)是教师对第i类的软概率，由教师 $logit(v_i)$通过T下的 $softmax$ 生成：$p_i = \frac{exp(v_i / T)}{\sum_j exp(v_j / T)}$；
- 学生模型预测的软概率为$q = [q_1, q_2,..., q_N]$（由学生 $logit(z_i)$通过相同T下的 $softmax$生成）；
  
则**软目标交叉熵损失**为：$$L_{soft} = -\sum_{i=1}^N p_i \cdot log(q_i)$$
- 在最后，软目标的损失函数比重要设计的远大于硬标签
则**最终蒸馏损失**为：$$L_{distill} = (1 - \alpha) \cdot T^2 \cdot L_{soft} + \alpha \cdot L_{hard}$$
## 实验
### 试验结果1——自定义模型
#### 教师
![[Pasted image 20250913211550.png]]
![[Pasted image 20250913211609.png]]
- 最高准确率达
![[Pasted image 20250913211658.png]]
![[Pasted image 20250913212439.png]]

#### 基线
![[Pasted image 20250913214415.png]]
![[Pasted image 20250913214436.png]]
![[Pasted image 20250913214523.png]]
![[Pasted image 20250913214542.png]]
#### 学生
![[Pasted image 20250913221157.png]]
![[Pasted image 20250913221216.png]]
![[Pasted image 20250913221241.png]]
![[Pasted image 20250913221314.png]]

![[Pasted image 20250913221130.png]]
#### 验证集
![[Pasted image 20250913221341.png]]

### 试验结果2——ResNet模型
#### 教师
- 损失
![[Pasted image 20250916182644.png]]
![[Pasted image 20250916182707.png]]
- 准确率 —— 在训练集上达到了94.5以上，非常亮眼
![[Pasted image 20250916182748.png]]
![[Pasted image 20250916182959.png]]
#### 基线
- 损失，在2以上，相较于teacher逊色许多，不过训练时不稳定，震荡程度大
![[Pasted image 20250916183044.png]]
![[Pasted image 20250916183207.png]]
- 准确率——震荡十分明显，可能是由于lr高
![[Pasted image 20250916183342.png]]
对于epoch的训练集准确率到达了92.5的水平，也是稍微逊色
![[Pasted image 20250916183315.png]]

#### 学生
- 损失（两张图标签颠倒了）
震荡程度很小，但是损失值比较大
![[Pasted image 20250916183710.png]]
![[Pasted image 20250916183729.png]]
- 分类损失
硬标签的损失十分的高，他和正确标签之间存在一些距离（一部分来源于软标签的T值）
![[Pasted image 20250916183813.png]]
软标签的震荡十分大，也是保持在0.3之上，值也很大
![[Pasted image 20250916183920.png]]
- 准确率——准确率十分高，在baseline的92.5和教师模型的94.5之间，达到了93
![[Pasted image 20250916184101.png]]
小模型震荡的比较严重
![[Pasted image 20250916184242.png]]


#### 验证集
来看看泛化的表现
- teacher——在epoch30最佳模型达到了93.67%的准确率，在跳出了局部最小值后十分平稳
![[Pasted image 20250916182918.png]]
- baseline——在epoch33最佳模型达到了92.29%的准确率，训练不平稳，比教师模型差了1.5%
![[Pasted image 20250916184528.png]]
- student——在epoch33和epoch47都达到了93.05%左右的正确率，收敛后基本平稳，相较于基线模型，有接近0.8%的提升。
![[Pasted image 20250916184711.png]]

### 结果分析


> 1. 模型的表现

| 模型                 | 参数量             | 训练集Accuracy | 测试集Accuracy |
| ------------------ | --------------- | ----------- | ----------- |
| teacher（ResNet）    | 1351.1K ~ 1.35M | **95.59%**  | **93.67%**  |
| baseline（简单卷积）     | 175K ~ 1.75M    | 92.50%      | 92.29%      |
| student（同baseline） | 175K ~ 1.75M    | 93.09%      | 93.05%      |
在模型架构和参数量相等的条件下
- **训练速度**：蒸馏模型比空白模型收敛更快
- **训练稳定性**：在损失函数方面，蒸馏模型不稳定；然而在体现模型真实表现的验证集上，却蒸馏模型更稳定
- **准确性/泛化能力**：在拟合训练集时，蒸馏模型获得更好效果，搞了绝对0.5%，并且在泛化能力上，蒸馏模型也更加强大，接近教师模型的表现


> 2. 模型出错分析

![[Pasted image 20250916232752.png]]
观察teacher和baseline模型，两者出奇的一致，分布很相同。
学生模型在蒸馏之后，对于类别6明显出错有所减少。
相较于baseline，student模型出错的概率情况比较平均。